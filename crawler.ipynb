{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f490165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:53:41.674385Z",
     "start_time": "2022-12-19T02:53:41.653400Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#- HTML 문서를 문자열 html로 저장합니다.\n",
    "html = '''\n",
    "<html> \n",
    "    <head> \n",
    "    </head> \n",
    "    <body> \n",
    "        <h1> 장바구니\n",
    "            <p id='clothes' class='name' title='라운드티'> 라운드티\n",
    "                <span class = 'number'> 25 </span> \n",
    "                <span class = 'price'> 29000 </span> \n",
    "                <span class = 'menu'> 의류</span> \n",
    "                <a href = 'http://www.naver.com'> 바로가기 </a> \n",
    "            </p> \n",
    "            <p id='watch' class='name' title='시계'> 시계\n",
    "                <span class = 'number'> 28 </span>\n",
    "                <span class = 'price'> 32000 </span> \n",
    "                <span class = 'menu'> 악세서리 </span> \n",
    "                <a href = 'http://www.facebook.com'> 바로가기 </a> \n",
    "            </p> \n",
    "        </h1> \n",
    "    </body> \n",
    "</html>\n",
    "'''\n",
    "\n",
    "#- BeautifulSoup 인스턴스를 생성합니다.\n",
    "#- 두번째 매개변수는 분석할 분석기(parser)의 종류입니다.\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630dd07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:53:46.823856Z",
     "start_time": "2022-12-19T02:53:46.804868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<html>\n",
       "<head>\n",
       "</head>\n",
       "<body>\n",
       "<h1> 장바구니\n",
       "            <p class=\"name\" id=\"clothes\" title=\"라운드티\"> 라운드티\n",
       "                <span class=\"number\"> 25 </span>\n",
       "<span class=\"price\"> 29000 </span>\n",
       "<span class=\"menu\"> 의류</span>\n",
       "<a href=\"http://www.naver.com\"> 바로가기 </a>\n",
       "</p>\n",
       "<p class=\"name\" id=\"watch\" title=\"시계\"> 시계\n",
       "                <span class=\"number\"> 28 </span>\n",
       "<span class=\"price\"> 32000 </span>\n",
       "<span class=\"menu\"> 악세서리 </span>\n",
       "<a href=\"http://www.facebook.com\"> 바로가기 </a>\n",
       "</p>\n",
       "</h1>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf377539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:53:58.590191Z",
     "start_time": "2022-12-19T02:53:58.571201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body>\n",
      "<h1> 장바구니\n",
      "            <p class=\"name\" id=\"clothes\" title=\"라운드티\"> 라운드티\n",
      "                <span class=\"number\"> 25 </span>\n",
      "<span class=\"price\"> 29000 </span>\n",
      "<span class=\"menu\"> 의류</span>\n",
      "<a href=\"http://www.naver.com\"> 바로가기 </a>\n",
      "</p>\n",
      "<p class=\"name\" id=\"watch\" title=\"시계\"> 시계\n",
      "                <span class=\"number\"> 28 </span>\n",
      "<span class=\"price\"> 32000 </span>\n",
      "<span class=\"menu\"> 악세서리 </span>\n",
      "<a href=\"http://www.facebook.com\"> 바로가기 </a>\n",
      "</p>\n",
      "</h1>\n",
      "</body>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.select('body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d303116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:54:06.108735Z",
     "start_time": "2022-12-19T02:54:06.097740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"menu\"> 의류</span>, <span class=\"menu\"> 악세서리 </span>]\n"
     ]
    }
   ],
   "source": [
    "print(soup.select('h1 .name .menu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8033338c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:57:24.036272Z",
     "start_time": "2022-12-19T02:57:23.208750Z"
    }
   },
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "#- 파싱할 뉴스 기사 주소입니다.\n",
    "url = 'https://n.news.naver.com/mnews/article/029/0002766294?sid=104'\n",
    "\n",
    "#- 언어가 한국어이므로 language='ko'로 설정해줍니다.\n",
    "article = Article(url, language='ko')\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "248bee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T02:57:30.485091Z",
     "start_time": "2022-12-19T02:57:30.475095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 제목 :\n",
      "트위터서 밤새며 일하는 머스크 \"테슬라 일도 한다\"\n",
      "\n",
      "기사 내용 :\n",
      "소셜미디어 트위터를 인수한 테슬라 최고경영자(CEO) 일론 머스크가 트위터 업무에 집중해 테슬라 경영을 소홀히 한다는 지적을 의식한 듯 \"트위터 일과 함께 테슬라 업무도 봤다\"는 트윗을 올렸다. 그러면서 \"이번주 중 테슬라 업무도 챙겨보겠다\"고 밝혔다.14일(현지시간) 블룸버그통신에 따르면 머스크는 자신을 고문하듯 일주일 내내 트위터 업무를 하고 있다고 말했다. 인도네시아 발리에서 주요 20개국 정상회의(G20)와 함께 진행된 기업인 회의인 비즈니스20 서밋(B20)에 화상으로 참석해서 한 말이다.머스크는 \"내가 처리해야 할 일이 너무 많다. 할 수 있는 한 최대한 일을 하고 있다\"면서 \"아침부터 저녁까지 일주일에 7일을 일한다. 솔직히 말해 나 자신을 고문하는 정도는 극단적인 수준\"이라고 밝혔다.그는 B20 회의 이후에는 트위터에 글을 올려 트위터 본사에서 밤을 샜고 조직이 고쳐질 때까지 회사에서 일하고 잠잘 것이라고 밝혔다. 한편 머스크가 트위터를 인수한 후 회사 내부에서는 '직원들을 24시간 일하는 로봇으로 취급한다'는 등의 비판이 쏟아지고 있다.\n"
     ]
    }
   ],
   "source": [
    "#- 기사 제목을 출력합니다.\n",
    "print('기사 제목 :')\n",
    "print(article.title)\n",
    "print('')\n",
    "\n",
    "#- 기사 내용을 출력합니다.\n",
    "print('기사 내용 :')\n",
    "print(article.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b29f5b",
   "metadata": {},
   "source": [
    "&sid1= 뒤에 있는 번호는 뉴스가 속한 카테고리의 번호를 의미합니다. 각 번호가 의미하는 카테고리는 다음과 같습니다. 실제로 눌러보면서 카테고리 번호가 어떻게 변경되는지를 확인하면 됩니다.  \n",
    "  \n",
    "100 : 정치  \n",
    "101 : 경제  \n",
    "102 : 사회  \n",
    "103 : 생활/문화  \n",
    "104 : 세계  \n",
    "105 : IT/과학  \n",
    "110 : 오피니언  \n",
    "&sid2= 뒤에 있는 번호는 뉴스가 속한 세부 카테고리의 번호를 의미합니다. 각 번호가 의미하는 카테고리는 다음과 같습니다. 실제로 눌러보면서 카테고리 번호가 어떻게 변경되는지를 확인하면 됩니다.  \n",
    "  \n",
    "731 : 모바일  \n",
    "226 : 인터넷/SNS  \n",
    "227 : 통신/뉴미디어  \n",
    "230 : IT 일반  \n",
    "732 : 보안/해킹   \n",
    "283 : 컴퓨터  \n",
    "&date= 뒤에 있는 날짜는 해당 뉴스들이 속한 날짜를 의미합니다. 이 날짜를 변경함으로써 해당 날짜의 뉴스 기사가 있는 페이지로 이동할 수 있습니다.  \n",
    "  \n",
    "&page= 뒤에 있는 번호는 몇 페이지인지를 의미합니다. 1페이지에서 크롤링을 다 하면, 2페이지로 이동하여 크롤링하고, 이런 식으로 페이지를 이동할 수 있겠죠?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74495715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T03:02:12.290755Z",
     "start_time": "2022-12-19T03:02:10.722417Z"
    }
   },
   "outputs": [],
   "source": [
    "# 크롤러를 만들기 전 필요한 도구들을 임포트합니다.\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 페이지 수, 카테고리, 날짜를 입력값으로 받습니다.\n",
    "def make_urllist(page_num, code1, code2, date): \n",
    "  urllist= []\n",
    "  for i in range(1, page_num + 1):\n",
    "    url = 'https://news.naver.com/main/list.naver?mode=LS2D&mid=shm'+'&sid2='+str(code2)+'&sid1='+str(code1)+'&date='+str(date)+'&page='+str(i)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.90 Safari/537.36'}\n",
    "    news = requests.get(url, headers=headers)\n",
    "\n",
    "    # BeautifulSoup의 인스턴스 생성합니다. 파서는 html.parser를 사용합니다.\n",
    "    soup = BeautifulSoup(news.content, 'html.parser')\n",
    "\n",
    "    # CASE 1\n",
    "    news_list = soup.select('.newsflash_body .type06_headline li dl')\n",
    "    # CASE 2\n",
    "    news_list.extend(soup.select('.newsflash_body .type06 li dl'))\n",
    "        \n",
    "    # 각 뉴스로부터 a 태그인 <a href ='주소'> 에서 '주소'만을 가져옵니다.\n",
    "    for line in news_list:\n",
    "        urllist.append(line.a.get('href'))\n",
    "  return urllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf02984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수입니다.\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = tokenizer.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2824dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:35:07.164962Z",
     "start_time": "2022-12-19T05:35:07.155967Z"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fb8ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:16:25.447610Z",
     "start_time": "2022-12-19T05:16:17.440335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['밤', '귀가', '여성', '범죄', '시도', '남성', '구속', '서울', '경찰서', '상해', '혐의', '씨', '구속', '수사', '일', '씨', '지난달', '일', '피해', '여성', '인근', '지하철', '역', '폭행', '시도', '혐의', '피해', '여성', '저항', '놀란', '씨', '신고', '주변', '수색', '경찰', '체포', '피해', '여성', '이', '과정', '부상', '것']\n",
      "['밤', '귀가', '여성', '범죄', '시도', '대', '남성', '구속됐다서울', '제주경찰', '혐의', '씨', '구속해', '수사', '일', '밝혔다씨', '지난달', '일', '여성', '인근', '지하철', '역', '폭행', '시도', '혐의', '받는다피해', '여성', '저항', '씨', '신고', '주변', '수색', '경찰', '체포됐다피해', '여성', '과정', '경미한', '부상', '입', '것']\n",
      "['밤', '귀가', '여성', '범죄', '시도', '대', '남성', '구속', '서울', '제주', '제주경찰서', '경찰서', '상해', '혐의', '씨', '수사', '일', '지난달', '피해', '인근', '지하철', '역', '폭행을', '저항', '신고', '주변', '수색', '경찰', '체포', '과정', '부상']\n",
      "['밤', '귀가', '여성', '범죄', '시도', '대', '남성', '구속', '다', '서울', '제주', '경찰서', '상해', '혐의', '씨', '구속', '수사', '일', '씨', '지난달', '일', '피해', '여성', '인근', '지하철', '역', '폭행', '시도', '혐의', '여성', '저항', '씨', '신고', '주변', '수색', '경찰', '체포', '여성', '과정', '부상', '것']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
    "okt = Okt()\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "\n",
    "kor_text = '밤에 귀가하던 여성에게 범죄를 시도한 대 남성이 구속됐다서울 제주경찰서는 \\\n",
    "            상해 혐의로 씨를 구속해 수사하고 있다고 일 밝혔다씨는 지난달 일 피해 여성을 \\\n",
    "            인근 지하철 역에서부터 따라가 폭행을 시도하려다가 도망간 혐의를 받는다피해 \\\n",
    "            여성이 저항하자 놀란 씨는 도망갔으며 신고를 받고 주변을 수색하던 경찰에 \\\n",
    "            체포됐다피해 여성은 이 과정에서 경미한 부상을 입은 것으로 전해졌다'\n",
    "\n",
    "print(okt.nouns(kor_text))\n",
    "print(hannanum.nouns(kor_text))\n",
    "print(kkma.nouns(kor_text))\n",
    "print(komoran.nouns(kor_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863c659",
   "metadata": {},
   "source": [
    "나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bfd91ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:22:14.899155Z",
     "start_time": "2022-12-19T05:22:14.710263Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511da71c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-19T05:22:15.904088Z",
     "start_time": "2022-12-19T05:22:15.862112Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_73684\\3395700892.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#- 훈련 데이터와 테스트 데이터를 분리합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'code1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text_data' is not defined"
     ]
    }
   ],
   "source": [
    "#- 훈련 데이터와 테스트 데이터를 분리합니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code1'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888680ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('훈련용 뉴스 기사의 개수 :', len(X_train))\n",
    "print('테스트용 뉴스 기사의 개수 : ', len(X_test))\n",
    "print('훈련용 레이블의 개수 : ', len(y_train))\n",
    "print('테스트용 레이블의 개수 : ', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- 단어의 수를 카운트하는 사이킷런의 카운트벡터라이저입니다.\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "#- 카운트벡터라이저의 결과로부터 TF-IDF 결과를 얻습니다.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "#- 나이브 베이즈 분류기를 수행합니다.\n",
    "#- X_train은 TF-IDF 벡터, y_train은 레이블입니다.\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a316a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent = preprocessing([\"민주당 일각에서 법사위의 체계·자구 심사 기능을 없애야 한다는 \\\n",
    "                           주장이 나오는 데 대해 “체계·자구 심사가 법안 지연의 수단으로 \\\n",
    "                          쓰이는 것은 바람직하지 않다”면서도 “국회를 통과하는 법안 중 위헌\\\n",
    "                          법률이 1년에 10건 넘게 나온다. 그런데 체계·자구 심사까지 없애면 매우 위험하다”고 반박했다.\"])\n",
    "print(clf.predict(tfidf_vectorizer(new_sent)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
